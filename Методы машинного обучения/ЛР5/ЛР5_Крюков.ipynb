{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ЛР5 - Крюков Г.М. - ИУ5-21М.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xZpoo218Y2Ay"
      },
      "outputs": [],
      "source": [
        "text = '''С минувшего сезона в Формуле 1 ввели лимит бюджетов, который регулирует затраты команд чемпионата на протяжении всего календарного года.\n",
        "Ограничения не включают в себя зарплаты гонщиков и трех главных сотрудников, а также траты на перелеты, отпуска и менеджмент – соответственно,\n",
        "командам нужно вписываться в денежный «потолок» только по издержкам, связанным с работой над машинами, включая зарплаты подавляющего большинства членов команды.'''\n",
        "text2 = 'Если установить планку максимального дохода пилотов, это может подстегнуть коллективы задуматься о выборе между приглашением звезд спорта и дополнительными тратами на развитии своего автомобиля.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np693nsfbKDv",
        "outputId": "65a82430-c722-475c-da2d-201b16281ca3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 145 kB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 97 kB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=04f6762984fea3d2290ba16d196920c4125386a654620c8e511c3c690d17f6d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Задача токенизации"
      ],
      "metadata": {
        "id": "6D29cTbU76Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize"
      ],
      "metadata": {
        "id": "g976JvjQaEX-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_tok_text = list(tokenize(text))\n",
        "n_tok_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ5RiWNraFGc",
        "outputId": "68442c18-792a-4782-d3c4-30d670bd7215"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 1, 'С'),\n",
              " Substring(2, 11, 'минувшего'),\n",
              " Substring(12, 18, 'сезона'),\n",
              " Substring(19, 20, 'в'),\n",
              " Substring(21, 28, 'Формуле'),\n",
              " Substring(29, 30, '1'),\n",
              " Substring(31, 36, 'ввели'),\n",
              " Substring(37, 42, 'лимит'),\n",
              " Substring(43, 51, 'бюджетов'),\n",
              " Substring(51, 52, ','),\n",
              " Substring(53, 60, 'который'),\n",
              " Substring(61, 71, 'регулирует'),\n",
              " Substring(72, 79, 'затраты'),\n",
              " Substring(80, 86, 'команд'),\n",
              " Substring(87, 97, 'чемпионата'),\n",
              " Substring(98, 100, 'на'),\n",
              " Substring(101, 111, 'протяжении'),\n",
              " Substring(112, 117, 'всего'),\n",
              " Substring(118, 130, 'календарного'),\n",
              " Substring(131, 135, 'года'),\n",
              " Substring(135, 136, '.'),\n",
              " Substring(137, 148, 'Ограничения'),\n",
              " Substring(149, 151, 'не'),\n",
              " Substring(152, 160, 'включают'),\n",
              " Substring(161, 162, 'в'),\n",
              " Substring(163, 167, 'себя'),\n",
              " Substring(168, 176, 'зарплаты'),\n",
              " Substring(177, 185, 'гонщиков'),\n",
              " Substring(186, 187, 'и'),\n",
              " Substring(188, 192, 'трех'),\n",
              " Substring(193, 200, 'главных'),\n",
              " Substring(201, 212, 'сотрудников'),\n",
              " Substring(212, 213, ','),\n",
              " Substring(214, 215, 'а'),\n",
              " Substring(216, 221, 'также'),\n",
              " Substring(222, 227, 'траты'),\n",
              " Substring(228, 230, 'на'),\n",
              " Substring(231, 239, 'перелеты'),\n",
              " Substring(239, 240, ','),\n",
              " Substring(241, 248, 'отпуска'),\n",
              " Substring(249, 250, 'и'),\n",
              " Substring(251, 261, 'менеджмент'),\n",
              " Substring(262, 263, '–'),\n",
              " Substring(264, 278, 'соответственно'),\n",
              " Substring(278, 279, ','),\n",
              " Substring(280, 288, 'командам'),\n",
              " Substring(289, 294, 'нужно'),\n",
              " Substring(295, 306, 'вписываться'),\n",
              " Substring(307, 308, 'в'),\n",
              " Substring(309, 317, 'денежный'),\n",
              " Substring(318, 319, '«'),\n",
              " Substring(319, 326, 'потолок'),\n",
              " Substring(326, 327, '»'),\n",
              " Substring(328, 334, 'только'),\n",
              " Substring(335, 337, 'по'),\n",
              " Substring(338, 347, 'издержкам'),\n",
              " Substring(347, 348, ','),\n",
              " Substring(349, 358, 'связанным'),\n",
              " Substring(359, 360, 'с'),\n",
              " Substring(361, 368, 'работой'),\n",
              " Substring(369, 372, 'над'),\n",
              " Substring(373, 381, 'машинами'),\n",
              " Substring(381, 382, ','),\n",
              " Substring(383, 390, 'включая'),\n",
              " Substring(391, 399, 'зарплаты'),\n",
              " Substring(400, 412, 'подавляющего'),\n",
              " Substring(413, 424, 'большинства'),\n",
              " Substring(425, 431, 'членов'),\n",
              " Substring(432, 439, 'команды'),\n",
              " Substring(439, 440, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_tok_text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4-R7DHaP2-",
        "outputId": "8e4ebcda-8ed9-4cb7-8e2a-c671993cc6a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['С',\n",
              " 'минувшего',\n",
              " 'сезона',\n",
              " 'в',\n",
              " 'Формуле',\n",
              " '1',\n",
              " 'ввели',\n",
              " 'лимит',\n",
              " 'бюджетов',\n",
              " ',',\n",
              " 'который',\n",
              " 'регулирует',\n",
              " 'затраты',\n",
              " 'команд',\n",
              " 'чемпионата',\n",
              " 'на',\n",
              " 'протяжении',\n",
              " 'всего',\n",
              " 'календарного',\n",
              " 'года',\n",
              " '.',\n",
              " 'Ограничения',\n",
              " 'не',\n",
              " 'включают',\n",
              " 'в',\n",
              " 'себя',\n",
              " 'зарплаты',\n",
              " 'гонщиков',\n",
              " 'и',\n",
              " 'трех',\n",
              " 'главных',\n",
              " 'сотрудников',\n",
              " ',',\n",
              " 'а',\n",
              " 'также',\n",
              " 'траты',\n",
              " 'на',\n",
              " 'перелеты',\n",
              " ',',\n",
              " 'отпуска',\n",
              " 'и',\n",
              " 'менеджмент',\n",
              " '–',\n",
              " 'соответственно',\n",
              " ',',\n",
              " 'командам',\n",
              " 'нужно',\n",
              " 'вписываться',\n",
              " 'в',\n",
              " 'денежный',\n",
              " '«',\n",
              " 'потолок',\n",
              " '»',\n",
              " 'только',\n",
              " 'по',\n",
              " 'издержкам',\n",
              " ',',\n",
              " 'связанным',\n",
              " 'с',\n",
              " 'работой',\n",
              " 'над',\n",
              " 'машинами',\n",
              " ',',\n",
              " 'включая',\n",
              " 'зарплаты',\n",
              " 'подавляющего',\n",
              " 'большинства',\n",
              " 'членов',\n",
              " 'команды',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_text = list(sentenize(text))\n",
        "n_sen_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3qQdSq5aQqO",
        "outputId": "f6130e58-d83e-4bbc-d0eb-d5c3a3f0d143"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0,\n",
              "           136,\n",
              "           'С минувшего сезона в Формуле 1 ввели лимит бюджетов, который регулирует затраты команд чемпионата на протяжении всего календарного года.'),\n",
              " Substring(137,\n",
              "           440,\n",
              "           'Ограничения не включают в себя зарплаты гонщиков и трех главных сотрудников, а также траты на перелеты, отпуска и менеджмент – соответственно,\\nкомандам нужно вписываться в денежный «потолок» только по издержкам, связанным с работой над машинами, включая зарплаты подавляющего большинства членов команды.')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSsI-IsGjk9i",
        "outputId": "3d1c341c-0b2c-4ba0-cc37-71389aae6024"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['С минувшего сезона в Формуле 1 ввели лимит бюджетов, который регулирует затраты команд чемпионата на протяжении всего календарного года.',\n",
              "  'Ограничения не включают в себя зарплаты гонщиков и трех главных сотрудников, а также траты на перелеты, отпуска и менеджмент – соответственно,\\nкомандам нужно вписываться в денежный «потолок» только по издержкам, связанным с работой над машинами, включая зарплаты подавляющего большинства членов команды.'],\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот вариант токенизации нужен для последующей обработки\n",
        "def n_sentenize(text):\n",
        "    n_sen_chunk = []\n",
        "    for sent in sentenize(text):\n",
        "        tokens = [_.text for _ in tokenize(sent.text)]\n",
        "        n_sen_chunk.append(tokens)\n",
        "    return n_sen_chunk"
      ],
      "metadata": {
        "id": "1-LaovsnjtZk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk = n_sentenize(text)\n",
        "n_sen_chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9y8VzzhjvHt",
        "outputId": "7340f2af-1102-4f5b-ae36-3cf152a424ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['С',\n",
              "  'минувшего',\n",
              "  'сезона',\n",
              "  'в',\n",
              "  'Формуле',\n",
              "  '1',\n",
              "  'ввели',\n",
              "  'лимит',\n",
              "  'бюджетов',\n",
              "  ',',\n",
              "  'который',\n",
              "  'регулирует',\n",
              "  'затраты',\n",
              "  'команд',\n",
              "  'чемпионата',\n",
              "  'на',\n",
              "  'протяжении',\n",
              "  'всего',\n",
              "  'календарного',\n",
              "  'года',\n",
              "  '.'],\n",
              " ['Ограничения',\n",
              "  'не',\n",
              "  'включают',\n",
              "  'в',\n",
              "  'себя',\n",
              "  'зарплаты',\n",
              "  'гонщиков',\n",
              "  'и',\n",
              "  'трех',\n",
              "  'главных',\n",
              "  'сотрудников',\n",
              "  ',',\n",
              "  'а',\n",
              "  'также',\n",
              "  'траты',\n",
              "  'на',\n",
              "  'перелеты',\n",
              "  ',',\n",
              "  'отпуска',\n",
              "  'и',\n",
              "  'менеджмент',\n",
              "  '–',\n",
              "  'соответственно',\n",
              "  ',',\n",
              "  'командам',\n",
              "  'нужно',\n",
              "  'вписываться',\n",
              "  'в',\n",
              "  'денежный',\n",
              "  '«',\n",
              "  'потолок',\n",
              "  '»',\n",
              "  'только',\n",
              "  'по',\n",
              "  'издержкам',\n",
              "  ',',\n",
              "  'связанным',\n",
              "  'с',\n",
              "  'работой',\n",
              "  'над',\n",
              "  'машинами',\n",
              "  ',',\n",
              "  'включая',\n",
              "  'зарплаты',\n",
              "  'подавляющего',\n",
              "  'большинства',\n",
              "  'членов',\n",
              "  'команды',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk_2 = n_sentenize(text2)\n",
        "n_sen_chunk_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn4MxoHwocQ8",
        "outputId": "287ca697-921b-4bfd-b8b5-f2c670ce1053"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Если',\n",
              "  'установить',\n",
              "  'планку',\n",
              "  'максимального',\n",
              "  'дохода',\n",
              "  'пилотов',\n",
              "  ',',\n",
              "  'это',\n",
              "  'может',\n",
              "  'подстегнуть',\n",
              "  'коллективы',\n",
              "  'задуматься',\n",
              "  'о',\n",
              "  'выборе',\n",
              "  'между',\n",
              "  'приглашением',\n",
              "  'звезд',\n",
              "  'спорта',\n",
              "  'и',\n",
              "  'дополнительными',\n",
              "  'тратами',\n",
              "  'на',\n",
              "  'развитии',\n",
              "  'своего',\n",
              "  'автомобиля',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Частеречная разметка"
      ],
      "metadata": {
        "id": "aWPyU6o68IxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from navec import Navec\n",
        "from slovnet import Morph"
      ],
      "metadata": {
        "id": "OJ5AC_rBj7Au"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
        "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
      ],
      "metadata": {
        "id": "GnUNaqiGj9x4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
        "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
      ],
      "metadata": {
        "id": "JIbJX44Ck5TR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_res = n_morph.navec(navec)"
      ],
      "metadata": {
        "id": "VGmz2S2OlB-x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pos(markup):\n",
        "    for token in markup.tokens:\n",
        "        print('{} - {}'.format(token.text, token.tag))"
      ],
      "metadata": {
        "id": "PHeplM8slDbu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
        "[print_pos(x) for x in n_text_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox7jury8lGBs",
        "outputId": "b0c8a15c-e18d-4faf-8795-6d2d9fd90024"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "С - ADP\n",
            "минувшего - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "сезона - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "Формуле - PROPN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            "1 - NUM\n",
            "ввели - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "лимит - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "бюджетов - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "который - PRON|Case=Nom|Gender=Masc|Number=Sing\n",
            "регулирует - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "затраты - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
            "команд - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
            "чемпионата - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "на - ADP\n",
            "протяжении - NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "всего - DET|Case=Gen|Gender=Masc|Number=Sing\n",
            "календарного - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "года - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Ограничения - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Plur\n",
            "не - PART|Polarity=Neg\n",
            "включают - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "в - ADP\n",
            "себя - PRON|Case=Acc\n",
            "зарплаты - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
            "гонщиков - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            "и - CCONJ\n",
            "трех - NUM|Animacy=Anim|Case=Acc\n",
            "главных - ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
            "сотрудников - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "а - CCONJ\n",
            "также - ADV|Degree=Pos\n",
            "траты - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Plur\n",
            "на - ADP\n",
            "перелеты - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "отпуска - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "и - CCONJ\n",
            "менеджмент - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            "– - PUNCT\n",
            "соответственно - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "командам - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Plur\n",
            "нужно - ADJ|Degree=Pos|Gender=Neut|Number=Sing|Variant=Short\n",
            "вписываться - VERB|Aspect=Imp|VerbForm=Inf|Voice=Mid\n",
            "в - ADP\n",
            "денежный - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
            "« - PUNCT\n",
            "потолок - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "» - PUNCT\n",
            "только - PART\n",
            "по - ADP\n",
            "издержкам - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Plur\n",
            ", - PUNCT\n",
            "связанным - VERB|Aspect=Perf|Case=Dat|Number=Plur|Tense=Past|VerbForm=Part|Voice=Pass\n",
            "с - ADP\n",
            "работой - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
            "над - ADP\n",
            "машинами - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Plur\n",
            ", - PUNCT\n",
            "включая - ADV|Degree=Pos\n",
            "зарплаты - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
            "подавляющего - ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
            "большинства - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "членов - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            "команды - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
        "[print_pos(x) for x in n_text2_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lR8begRoh2Y",
        "outputId": "16e8fcf0-3f9a-4fba-979c-882679406bb4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Если - SCONJ\n",
            "установить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "планку - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "максимального - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "дохода - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "пилотов - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            ", - PUNCT\n",
            "это - PRON|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
            "может - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "подстегнуть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "коллективы - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "задуматься - VERB|Aspect=Perf|VerbForm=Inf|Voice=Mid\n",
            "о - ADP\n",
            "выборе - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            "между - ADP\n",
            "приглашением - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n",
            "звезд - NOUN|Animacy=Anim|Case=Gen|Gender=Fem|Number=Plur\n",
            "спорта - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "и - CCONJ\n",
            "дополнительными - ADJ|Case=Ins|Degree=Pos|Number=Plur\n",
            "тратами - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Plur\n",
            "на - ADP\n",
            "развитии - NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "своего - DET|Case=Gen|Gender=Masc|Number=Sing\n",
            "автомобиля - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Лемматизация"
      ],
      "metadata": {
        "id": "g0okcggK8RyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
      ],
      "metadata": {
        "id": "MwcHLMPxlZbv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_lemmatize(text):\n",
        "    emb = NewsEmbedding()\n",
        "    morph_tagger = NewsMorphTagger(emb)\n",
        "    segmenter = Segmenter()\n",
        "    morph_vocab = MorphVocab()\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for token in doc.tokens:\n",
        "        token.lemmatize(morph_vocab)\n",
        "    return doc"
      ],
      "metadata": {
        "id": "QiZyPQqClbSu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc = n_lemmatize(text)\n",
        "{_.text: _.lemma for _ in n_doc.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_vfR7milc_L",
        "outputId": "750e5ec6-d50d-4e55-b34d-fb4504eed6b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " '.': '.',\n",
              " '1': '1',\n",
              " '«': '«',\n",
              " '»': '»',\n",
              " 'Ограничения': 'ограничение',\n",
              " 'С': 'с',\n",
              " 'Формуле': 'формула',\n",
              " 'а': 'а',\n",
              " 'большинства': 'большинство',\n",
              " 'бюджетов': 'бюджет',\n",
              " 'в': 'в',\n",
              " 'ввели': 'ввести',\n",
              " 'включают': 'включать',\n",
              " 'включая': 'включая',\n",
              " 'вписываться': 'вписываться',\n",
              " 'всего': 'весь',\n",
              " 'главных': 'главный',\n",
              " 'года': 'год',\n",
              " 'гонщиков': 'гонщик',\n",
              " 'денежный': 'денежный',\n",
              " 'зарплаты': 'зарплата',\n",
              " 'затраты': 'затрата',\n",
              " 'и': 'и',\n",
              " 'издержкам': 'издержка',\n",
              " 'календарного': 'календарный',\n",
              " 'команд': 'команда',\n",
              " 'командам': 'команда',\n",
              " 'команды': 'команда',\n",
              " 'который': 'который',\n",
              " 'лимит': 'лимит',\n",
              " 'машинами': 'машина',\n",
              " 'менеджмент': 'менеджмент',\n",
              " 'минувшего': 'минувший',\n",
              " 'на': 'на',\n",
              " 'над': 'над',\n",
              " 'не': 'не',\n",
              " 'нужно': 'нужный',\n",
              " 'отпуска': 'отпуск',\n",
              " 'перелеты': 'перелет',\n",
              " 'по': 'по',\n",
              " 'подавляющего': 'подавлять',\n",
              " 'потолок': 'потолок',\n",
              " 'протяжении': 'протяжение',\n",
              " 'работой': 'работа',\n",
              " 'регулирует': 'регулировать',\n",
              " 'с': 'с',\n",
              " 'связанным': 'связать',\n",
              " 'себя': 'себя',\n",
              " 'сезона': 'сезон',\n",
              " 'соответственно': 'соответственно',\n",
              " 'сотрудников': 'сотрудник',\n",
              " 'также': 'также',\n",
              " 'только': 'только',\n",
              " 'траты': 'трата',\n",
              " 'трех': 'три',\n",
              " 'чемпионата': 'чемпионат',\n",
              " 'членов': 'член',\n",
              " '–': '–'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2 = n_lemmatize(text2)\n",
        "{_.text: _.lemma for _ in n_doc2.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQlhapPoooX",
        "outputId": "aa45ad65-ba44-4c31-9ca9-06c2d686bef1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " '.': '.',\n",
              " 'Если': 'если',\n",
              " 'автомобиля': 'автомобиль',\n",
              " 'выборе': 'выбор',\n",
              " 'дополнительными': 'дополнительный',\n",
              " 'дохода': 'доход',\n",
              " 'задуматься': 'задуматься',\n",
              " 'звезд': 'звезда',\n",
              " 'и': 'и',\n",
              " 'коллективы': 'коллектив',\n",
              " 'максимального': 'максимальный',\n",
              " 'между': 'между',\n",
              " 'может': 'мочь',\n",
              " 'на': 'на',\n",
              " 'о': 'о',\n",
              " 'пилотов': 'пилот',\n",
              " 'планку': 'планка',\n",
              " 'подстегнуть': 'подстегнуть',\n",
              " 'приглашением': 'приглашение',\n",
              " 'развитии': 'развитие',\n",
              " 'своего': 'свой',\n",
              " 'спорта': 'спорт',\n",
              " 'тратами': 'трата',\n",
              " 'установить': 'установить',\n",
              " 'это': 'это'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Выделение (распознавание) именованных сущностей"
      ],
      "metadata": {
        "id": "MGiHQ5nV8YHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slovnet import NER\n",
        "from ipymarkup import show_span_ascii_markup as show_markup"
      ],
      "metadata": {
        "id": "CX1Jn2LjllO4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = NER.load('slovnet_ner_news_v1.tar')"
      ],
      "metadata": {
        "id": "6jR1CB3clmoO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_res = ner.navec(navec)"
      ],
      "metadata": {
        "id": "EfcXKkyLlo_f"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markup_ner = ner(text2)\n",
        "markup_ner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUkgF6nVlrLY",
        "outputId": "f4b6b50b-1d82-4517-9019-dc77fcd24f8c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpanMarkup(\n",
              "    text='Если установить планку максимального дохода пилотов, это может подстегнуть коллективы задуматься о выборе между приглашением звезд спорта и дополнительными тратами на развитии своего автомобиля.',\n",
              "    spans=[]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_markup(markup_ner.text, markup_ner.spans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy-71aTplrGm",
        "outputId": "100f4e74-e5c7-4d7a-afd9-00c5a9f962f9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Если установить планку максимального дохода пилотов, это может \n",
            "подстегнуть коллективы задуматься о выборе между приглашением звезд \n",
            "спорта и дополнительными тратами на развитии своего автомобиля.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Разбор предложения"
      ],
      "metadata": {
        "id": "N1EEBFmk8ddx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import NewsSyntaxParser"
      ],
      "metadata": {
        "id": "w07LI_cdnt3A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = NewsEmbedding()\n",
        "syntax_parser = NewsSyntaxParser(emb)"
      ],
      "metadata": {
        "id": "ad3aEUqunyFr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbFuGGMinzZu",
        "outputId": "1ececcdb-1e76-4307-f86c-07090c6599ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ┌──► С            case\n",
            "      │ ┌► минувшего    amod\n",
            "  ┌──►└─└─ сезона       obl\n",
            "  │     ┌► в            case\n",
            "  │ ┌►┌─└─ Формуле      obl\n",
            "  │ │ └──► 1            appos\n",
            "┌─└─└───┌─ ввели        \n",
            "│   ┌─┌─└► лимит        obj\n",
            "│   │ └──► бюджетов     nmod\n",
            "│   │ ┌──► ,            punct\n",
            "│   │ │ ┌► который      nsubj\n",
            "│ ┌─└►└─└─ регулирует   acl:relcl\n",
            "│ │   └►┌─ затраты      obj\n",
            "│ │   ┌─└► команд       nmod\n",
            "│ │   └──► чемпионата   nmod\n",
            "│ │     ┌► на           case\n",
            "│ └►┌───└─ протяжении   obl\n",
            "│   │ ┌──► всего        det\n",
            "│   │ │ ┌► календарного amod\n",
            "│   └►└─└─ года         nmod\n",
            "└────────► .            punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[1].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc4OlSa1n08h",
        "outputId": "75170da2-223f-4b23-b874-aab908db2a92"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  ┌──► Ограничения    nsubj\n",
            "                  │ ┌► не             advmod\n",
            "┌─┌───┌───────┌─┌─└─└─ включают       \n",
            "│ │   │       │ │   ┌► в              case\n",
            "│ │   │       │ └──►└─ себя           obl\n",
            "│ │   │     ┌─└────►┌─ зарплаты       obj\n",
            "│ │   │   ┌─│ ┌─────└► гонщиков       nmod\n",
            "│ │   │   │ │ │ ┌────► и              cc\n",
            "│ │   │   │ │ │ │ ┌──► трех           nummod\n",
            "│ │   │   │ │ │ │ │ ┌► главных        amod\n",
            "│ │   │   │ │ └►└─└─└─ сотрудников    conj\n",
            "│ │   │   │ │   ┌────► ,              punct\n",
            "│ │   │   │ │   │ ┌►┌─ а              cc\n",
            "│ │   │   │ │   │ │ └► также          fixed\n",
            "│ │   │ ┌─│ └──►└─└─── траты          conj\n",
            "│ │   │ │ │     │   ┌► на             case\n",
            "│ │   │ │ │     └──►└─ перелеты       nmod\n",
            "│ │   │ │ │         ┌► ,              punct\n",
            "│ │   │ │ └────────►└─ отпуска        conj\n",
            "│ │   │ │           ┌► и              cc\n",
            "│ │ ┌►│ │           └─ менеджмент     conj\n",
            "│ │ │ │ │       ┌────► –              punct\n",
            "│ │ │ │ │       │ ┌►┌─ соответственно parataxis\n",
            "│ │ │ │ │       │ │ └► ,              punct\n",
            "│ │ │ │ │       │ │ ┌► командам       iobj\n",
            "│ │ │ └►│       └─└─└─ нужно          conj\n",
            "│ │ │   │         └──► вписываться    csubj\n",
            "│ │ │   │       ┌────► в              case\n",
            "│ │ │   │       │ ┌──► денежный       amod\n",
            "│ │ │   │       │ │ ┌► «              punct\n",
            "│ │ │   └──────►└─└─└─ потолок        nmod\n",
            "│ │ │             └──► »              punct\n",
            "│ │ │             ┌──► только         advmod\n",
            "│ │ │             │ ┌► по             case\n",
            "│ └►│     ┌─────┌─└─└─ издержкам      obl\n",
            "│   │     │     │   ┌► ,              punct\n",
            "│   │     │   ┌─└──►└─ связанным      acl\n",
            "│   │     │   │     ┌► с              case\n",
            "│   │     │ ┌─└────►└─ работой        obl\n",
            "│   │     │ │       ┌► над            case\n",
            "│   │     │ └──────►└─ машинами       nmod\n",
            "│   │     │         ┌► ,              punct\n",
            "│   │     └──────►┌─└─ включая        advmod\n",
            "│   └───────────┌─└──► зарплаты       obj\n",
            "│               │   ┌► подавляющего   amod\n",
            "│               └►┌─└─ большинства    nmod\n",
            "│                 └►┌─ членов         nmod\n",
            "│                   └► команды        nmod\n",
            "└────────────────────► .              punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2.parse_syntax(syntax_parser)\n",
        "n_doc2.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QcEdIjQoEX9",
        "outputId": "3d99e797-37aa-42e6-c54f-c6041a95ba6e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ┌► Если            mark\n",
            "  ┌►┌───┌─└─ установить      advcl\n",
            "  │ │ ┌─└──► планку          obj\n",
            "  │ │ │   ┌► максимального   amod\n",
            "  │ │ └►┌─└─ дохода          nmod\n",
            "  │ │   └──► пилотов         nmod\n",
            "  │ └──────► ,               punct\n",
            "  │       ┌► это             nsubj\n",
            "┌─└───┌─┌─└─ может           \n",
            "│     │ └►┌─ подстегнуть     xcomp\n",
            "│     │   └► коллективы      obj\n",
            "│     └►┌─── задуматься      xcomp\n",
            "│       │ ┌► о               case\n",
            "│ ┌───┌─└►└─ выборе          obl\n",
            "│ │   │   ┌► между           case\n",
            "│ │ ┌─└►┌─└─ приглашением    nmod\n",
            "│ │ │   └►┌─ звезд           nmod\n",
            "│ │ │     └► спорта          nmod\n",
            "│ │ │   ┌──► и               cc\n",
            "│ │ │   │ ┌► дополнительными amod\n",
            "│ │ └──►└─└─ тратами         conj\n",
            "│ │       ┌► на              case\n",
            "│ └────►┌─└─ развитии        nmod\n",
            "│       │ ┌► своего          det\n",
            "│       └►└─ автомобиля      nmod\n",
            "└──────────► .               punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ],
      "metadata": {
        "id": "-c2XPKKOq7Wu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Векторизация текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "bAzmgaJ_80sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.autos\", \"sci.space\",\"comp.windows.x\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "VLoXLDqzq4Ku"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "42Wh-CynrkGj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(data)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esrSY6qXrleU",
        "outputId": "142c1e13-bcda-40d8-bfbe-65c448729b0e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 35770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UA7wvzZsJxl",
        "outputId": "35ee569a-c6a7-4f04-d456-b5ba1965f4c8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicho=22808\n",
            "vnet=33598\n",
            "ibm=17519\n",
            "com=10099\n",
            "greg=16232\n",
            "stewart=30046\n",
            "nicholls=22810\n",
            "subject=30313\n",
            "re=26313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Использование класса CountVectorizer"
      ],
      "metadata": {
        "id": "p_MD1mfu9BUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = vocabVect.transform(data)\n",
        "test_features"
      ],
      "metadata": {
        "id": "EOcZ0afBs98g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e11715-8c00-4afe-eb5e-a0b46662094b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2378x35770 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 347775 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olYUOhsstEZ1",
        "outputId": "5eae538d-cc32-4ad0-932e-24273a91d743"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 1, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-56OfvNtH9r",
        "outputId": "8fca33b2-fe59-4521-d72d-3711ba7455b4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35770"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Непустые значения нулевой строки\n",
        "print([i for i in test_features.todense()[0].getA1() if i>0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lQND6-DtKEh",
        "outputId": "7d12dd0a-1302-4e4e-abf1-078fe38bb35c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 7, 1, 4, 2, 4, 1, 2, 1, 1, 1, 1, 1, 3, 1, 6, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 5, 2, 1, 3, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect.get_feature_names()[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMU_R7GtS6d",
        "outputId": "7a99c603-e97b-4284-bfd5-9fa32394cbc3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '00000',\n",
              " '000000',\n",
              " '00000000',\n",
              " '0000000004',\n",
              " '0000000005',\n",
              " '0000000667',\n",
              " '0000001200']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Решение задачи анализа тональности текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "JsJo3ST09MHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ],
      "metadata": {
        "id": "VV9Gdq0At4yY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdDlkVmyt9uu",
        "outputId": "f89004c8-4773-4e14-bf44-ef7ab72d3d96"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
            "                            '000000': 4, '00000000': 5, '0000000004': 6,\n",
            "                            '0000000005': 7, '0000000667': 8, '0000001200': 9,\n",
            "                            '00000074': 10, '00000093': 11, '000000e5': 12,\n",
            "                            '00000315': 13, '000005102000': 14,\n",
            "                            '00000510200001': 15, '00000ee5': 16,\n",
            "                            '000010af': 17, '000021': 18, '000062david42': 19,\n",
            "                            '0001': 20, '0001mpc': 21, '0002': 22, '0003': 23,\n",
            "                            '00041032': 24, '0004136': 25, '0004246': 26,\n",
            "                            '0004422': 27, '00044513': 28, '0004847546': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.9516412549199434\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
            "                            '000000': 4, '00000000': 5, '0000000004': 6,\n",
            "                            '0000000005': 7, '0000000667': 8, '0000001200': 9,\n",
            "                            '00000074': 10, '00000093': 11, '000000e5': 12,\n",
            "                            '00000315': 13, '000005102000': 14,\n",
            "                            '00000510200001': 15, '00000ee5': 16,\n",
            "                            '000010af': 17, '000021': 18, '000062david42': 19,\n",
            "                            '0001': 20, '0001mpc': 21, '0002': 22, '0003': 23,\n",
            "                            '00041032': 24, '0004136': 25, '0004246': 26,\n",
            "                            '0004422': 27, '00044513': 28, '0004847546': 29, ...})\n",
            "Модель для классификации - LinearSVC()\n",
            "Accuracy = 0.9529001660149201\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '00000': 3,\n",
            "                            '000000': 4, '00000000': 5, '0000000004': 6,\n",
            "                            '0000000005': 7, '0000000667': 8, '0000001200': 9,\n",
            "                            '00000074': 10, '00000093': 11, '000000e5': 12,\n",
            "                            '00000315': 13, '000005102000': 14,\n",
            "                            '00000510200001': 15, '00000ee5': 16,\n",
            "                            '000010af': 17, '000021': 18, '000062david42': 19,\n",
            "                            '0001': 20, '0001mpc': 21, '0002': 22, '0003': 23,\n",
            "                            '00041032': 24, '0004136': 25, '0004246': 26,\n",
            "                            '0004422': 27, '00044513': 28, '0004847546': 29, ...})\n",
            "Модель для классификации - KNeighborsClassifier()\n",
            "Accuracy = 0.6206813829764649\n",
            "===========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
      ],
      "metadata": {
        "id": "x2mfQKgl9RN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "m77McUr1uylj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "7g6e4RKBvIHn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(CountVectorizer(), LinearSVC())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcvoZrEgvFRk",
        "outputId": "1a00f35c-5979-445d-e98d-1019fd0a9a71"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9710610932475884\n",
            "1 \t 0.9161073825503355\n",
            "2 \t 0.9137931034482759\n",
            "3 \t 0.9413793103448276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Работа с векторными представлениями слов с использованием word2vec"
      ],
      "metadata": {
        "id": "M8gze-2y9bRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec"
      ],
      "metadata": {
        "id": "v7Y1WfrRwAWR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'"
      ],
      "metadata": {
        "id": "TatHWijIwB7r"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "metadata": {
        "id": "yqBiwzzlwE9W"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['формула_S', 'гонщик_S', 'трасса_S', 'пилот_S']"
      ],
      "metadata": {
        "id": "LgDxS_I6wIMh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    if word in model:\n",
        "        print('\\nСЛОВО - {}'.format(word))\n",
        "        print('5 ближайших соседей слова:')\n",
        "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
        "            print('{} => {}'.format(word, sim))\n",
        "    else:\n",
        "        print('Слово \"{}\" не найдено в модели'.format(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5v9XQQxHm1",
        "outputId": "2980c87a-92fd-4cef-ed27-c131320a4fbd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "СЛОВО - формула_S\n",
            "5 ближайших соседей слова:\n",
            "формулировка_S => 0.5704624652862549\n",
            "схема_S => 0.5608954429626465\n",
            "термин_S => 0.5511266589164734\n",
            "уравнение_S => 0.541883111000061\n",
            "дефиниция_S => 0.48302578926086426\n",
            "\n",
            "СЛОВО - гонщик_S\n",
            "5 ближайших соседей слова:\n",
            "пилот_S => 0.6352430582046509\n",
            "спортсмен_S => 0.6265261173248291\n",
            "футболист_S => 0.5708452463150024\n",
            "теннисист_S => 0.5618873834609985\n",
            "хоккеист_S => 0.5613346099853516\n",
            "\n",
            "СЛОВО - трасса_S\n",
            "5 ближайших соседей слова:\n",
            "шоссе_S => 0.6257457733154297\n",
            "автобан_S => 0.5925841331481934\n",
            "магистраль_S => 0.5805814862251282\n",
            "автомагистраль_S => 0.5543080568313599\n",
            "дорога_S => 0.5536060929298401\n",
            "\n",
            "СЛОВО - пилот_S\n",
            "5 ближайших соседей слова:\n",
            "летчик_S => 0.6687040328979492\n",
            "гонщик_S => 0.6352430582046509\n",
            "самолет_S => 0.5455822944641113\n",
            "космонавт_S => 0.5025683641433716\n",
            "авиатор_S => 0.49828794598579407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Находим близость между словами и строим аналогии"
      ],
      "metadata": {
        "id": "n0RDfHMr9sgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity('гонщик_S', 'пилот_S'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cTsFYXWxL9K",
        "outputId": "9f04947d-07ec-4a3c-9574-31d944e47c3e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.635243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(positive=['гонщик_S', 'пилот_S'], negative=['зритель_S']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI2D3nmtxMao",
        "outputId": "effd8362-88fb-4a91-880c-f630af041dff"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('летчик_S', 0.501598060131073), ('williams_UNKN', 0.46746107935905457), ('ferrari_UNKN', 0.4663965404033661), ('jordan_UNKN', 0.4330463111400604), ('mclaren_UNKN', 0.43209052085876465), ('arrows_UNKN', 0.42726415395736694), ('футболист_S', 0.42045044898986816), ('спортсмен_S', 0.4196248948574066), ('спарка_S', 0.4049972891807556), ('авиатор_S', 0.40437883138656616)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Обучим word2vec на наборе данных \"fetch_20newsgroups\""
      ],
      "metadata": {
        "id": "l3dZXqKE9zrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIABoRcH5tWG",
        "outputId": "c222bde5-20ec-4dc8-8462-bda0f9fb5e7b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.autos\", \"sci.space\",\"comp.windows.x\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "jZbwRKof5zb9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим корпус\n",
        "corpus = []\n",
        "stop_words = stopwords.words('english')\n",
        "tok = WordPunctTokenizer()\n",
        "for line in newsgroups['data']:\n",
        "    line1 = line.strip().lower()\n",
        "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
        "    text_tok = tok.tokenize(line1)\n",
        "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
        "    corpus.append(text_tok1)"
      ],
      "metadata": {
        "id": "qXFAWpOR6akB"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-8AkEoW6vg4",
        "outputId": "baa68891-695e-47d7-84b2-5b47b0236e92"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nicho',\n",
              "  'vnet',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'greg',\n",
              "  'stewart',\n",
              "  'nicholls',\n",
              "  'subject',\n",
              "  'biosphere',\n",
              "  'ii',\n",
              "  'reply',\n",
              "  'nicho',\n",
              "  'vnet',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'disclaimer',\n",
              "  'posting',\n",
              "  'represents',\n",
              "  'poster',\n",
              "  'views',\n",
              "  'ibm',\n",
              "  'news',\n",
              "  'software',\n",
              "  'ureply',\n",
              "  'x',\n",
              "  'x',\n",
              "  'nicho',\n",
              "  'vnet',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'q',\n",
              "  'kia',\n",
              "  'gg',\n",
              "  'access',\n",
              "  'digex',\n",
              "  'net',\n",
              "  'lines',\n",
              "  'q',\n",
              "  'kia',\n",
              "  'gg',\n",
              "  'access',\n",
              "  'digex',\n",
              "  'net',\n",
              "  'pat',\n",
              "  'writes',\n",
              "  'article',\n",
              "  'almaden',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'nicho',\n",
              "  'vnet',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'writes',\n",
              "  'q',\n",
              "  'ud',\n",
              "  'ji',\n",
              "  'access',\n",
              "  'digex',\n",
              "  'net',\n",
              "  'pat',\n",
              "  'writes',\n",
              "  'everyone',\n",
              "  'critical',\n",
              "  'b',\n",
              "  'bogus',\n",
              "  'science',\n",
              "  'promoted',\n",
              "  'real',\n",
              "  'science',\n",
              "  'seems',\n",
              "  'sorta',\n",
              "  'large',\n",
              "  'engineering',\n",
              "  'project',\n",
              "  'science',\n",
              "  'project',\n",
              "  'bingo',\n",
              "  'b',\n",
              "  'bench',\n",
              "  'science',\n",
              "  'rather',\n",
              "  'large',\n",
              "  'scale',\n",
              "  'attempt',\n",
              "  'create',\n",
              "  'series',\n",
              "  'micro',\n",
              "  'ecologies',\n",
              "  'eveil',\n",
              "  'nothing',\n",
              "  'evil',\n",
              "  'actual',\n",
              "  'harm',\n",
              "  'represent',\n",
              "  'sig',\n",
              "  'files',\n",
              "  'like',\n",
              "  'strings',\n",
              "  'every',\n",
              "  'yo',\n",
              "  'yo',\n",
              "  'got',\n",
              "  'one',\n",
              "  'greg',\n",
              "  'nicholls',\n",
              "  'nicho',\n",
              "  'vnet',\n",
              "  'ibm',\n",
              "  'com',\n",
              "  'business',\n",
              "  'nicho',\n",
              "  'olympus',\n",
              "  'demon',\n",
              "  'co',\n",
              "  'uk',\n",
              "  'private'],\n",
              " ['dmcaloon',\n",
              "  'tuba',\n",
              "  'calpoly',\n",
              "  'edu',\n",
              "  'david',\n",
              "  'mcaloon',\n",
              "  'subject',\n",
              "  'planets',\n",
              "  'still',\n",
              "  'images',\n",
              "  'orbit',\n",
              "  'ether',\n",
              "  'twist',\n",
              "  'organization',\n",
              "  'california',\n",
              "  'polytechnic',\n",
              "  'state',\n",
              "  'university',\n",
              "  'san',\n",
              "  'luis',\n",
              "  'obispo',\n",
              "  'lines',\n",
              "  'ether',\n",
              "  'implodes',\n",
              "  'earth',\n",
              "  'core',\n",
              "  'gravity',\n",
              "  'paper',\n",
              "  'describes',\n",
              "  'heavenly',\n",
              "  'bodys',\n",
              "  'stationary',\n",
              "  'ether',\n",
              "  'sucking',\n",
              "  'structures',\n",
              "  'observe',\n",
              "  'orbital',\n",
              "  'motion',\n",
              "  'ether',\n",
              "  'theoretical',\n",
              "  'propogation',\n",
              "  'media',\n",
              "  'electro',\n",
              "  'magnetic',\n",
              "  'waves',\n",
              "  'concluded',\n",
              "  'exist',\n",
              "  'based',\n",
              "  'results',\n",
              "  'michelson',\n",
              "  'moreley',\n",
              "  'experiment',\n",
              "  'conducted',\n",
              "  'century',\n",
              "  'ago',\n",
              "  'propose',\n",
              "  'conclusions',\n",
              "  'flawed',\n",
              "  'based',\n",
              "  'fact',\n",
              "  'experiment',\n",
              "  'designed',\n",
              "  'look',\n",
              "  'flow',\n",
              "  'parallel',\n",
              "  'earth',\n",
              "  'surface',\n",
              "  'perpindicular',\n",
              "  'due',\n",
              "  'prevailing',\n",
              "  'assumption',\n",
              "  'earth',\n",
              "  'traveled',\n",
              "  'ether',\n",
              "  'ball',\n",
              "  'wind',\n",
              "  'reversal',\n",
              "  'conclusion',\n",
              "  'pivotal',\n",
              "  'keystone',\n",
              "  'development',\n",
              "  'modern',\n",
              "  'scientific',\n",
              "  'thought',\n",
              "  'could',\n",
              "  'ramifications',\n",
              "  'biblical',\n",
              "  'proportions',\n",
              "  'world',\n",
              "  'remember',\n",
              "  'einstien',\n",
              "  'said',\n",
              "  'imagination',\n",
              "  'greater',\n",
              "  'knowledge',\n",
              "  'dream',\n",
              "  'like',\n",
              "  'ether',\n",
              "  'based',\n",
              "  'reality',\n",
              "  'ether',\n",
              "  'like',\n",
              "  'fluid',\n",
              "  'phase',\n",
              "  'reality',\n",
              "  'creations',\n",
              "  'start',\n",
              "  'lattice',\n",
              "  'placed',\n",
              "  'ether',\n",
              "  'given',\n",
              "  'spin',\n",
              "  'lattices',\n",
              "  'drag',\n",
              "  'fluid',\n",
              "  'like',\n",
              "  'margarita',\n",
              "  'blender',\n",
              "  'ingest',\n",
              "  'converting',\n",
              "  'distilling',\n",
              "  'localized',\n",
              "  'mass',\n",
              "  'time',\n",
              "  'energy',\n",
              "  'non',\n",
              "  'spinning',\n",
              "  'lattice',\n",
              "  'dark',\n",
              "  'matter',\n",
              "  'earth',\n",
              "  'exactly',\n",
              "  'spinning',\n",
              "  'around',\n",
              "  'sun',\n",
              "  'picture',\n",
              "  'image',\n",
              "  'galaxy',\n",
              "  'videos',\n",
              "  'spinning',\n",
              "  'picture',\n",
              "  'us',\n",
              "  'stationary',\n",
              "  'sun',\n",
              "  'image',\n",
              "  'dragged',\n",
              "  'across',\n",
              "  'sky',\n",
              "  'spinning',\n",
              "  'ether',\n",
              "  'field',\n",
              "  'picture',\n",
              "  'onion',\n",
              "  'layer',\n",
              "  'spinning',\n",
              "  'little',\n",
              "  'faster',\n",
              "  'next',\n",
              "  'thread',\n",
              "  'shot',\n",
              "  'inner',\n",
              "  'kernel',\n",
              "  'would',\n",
              "  'stretched',\n",
              "  'diagonally',\n",
              "  'sideways',\n",
              "  'head',\n",
              "  'faster',\n",
              "  'shell',\n",
              "  'tail',\n",
              "  'finally',\n",
              "  'intersected',\n",
              "  'ground',\n",
              "  'inner',\n",
              "  'kernel',\n",
              "  'direction',\n",
              "  'vector',\n",
              "  'straight',\n",
              "  'foot',\n",
              "  'print',\n",
              "  'line',\n",
              "  'point',\n",
              "  'sunrise',\n",
              "  'sunset',\n",
              "  'moon',\n",
              "  'exactly',\n",
              "  'orbiting',\n",
              "  'us',\n",
              "  'parasite',\n",
              "  'non',\n",
              "  'self',\n",
              "  'spin',\n",
              "  'sustaining',\n",
              "  'dragged',\n",
              "  'earth',\n",
              "  'ether',\n",
              "  'field',\n",
              "  'sun',\n",
              "  'much',\n",
              "  'powerful',\n",
              "  'field',\n",
              "  'seasons',\n",
              "  'wobble',\n",
              "  'earth',\n",
              "  'axis',\n",
              "  'like',\n",
              "  'top',\n",
              "  'slowing',\n",
              "  'orbit',\n",
              "  'earth',\n",
              "  'around',\n",
              "  'sun',\n",
              "  'stars',\n",
              "  'images',\n",
              "  'dragged',\n",
              "  'around',\n",
              "  'sun',\n",
              "  'ether',\n",
              "  'feild',\n",
              "  'earth',\n",
              "  'moon',\n",
              "  'sun',\n",
              "  'size',\n",
              "  'distance',\n",
              "  'apart',\n",
              "  'time',\n",
              "  'varies',\n",
              "  'greatly',\n",
              "  'path',\n",
              "  'moon',\n",
              "  'lattice',\n",
              "  'ether',\n",
              "  'like',\n",
              "  'sticking',\n",
              "  'fork',\n",
              "  'plate',\n",
              "  'spaghetti',\n",
              "  'giving',\n",
              "  'plate',\n",
              "  'half',\n",
              "  'turn',\n",
              "  'sun',\n",
              "  'lattice',\n",
              "  'much',\n",
              "  'spin',\n",
              "  'like',\n",
              "  'fork',\n",
              "  'got',\n",
              "  'whole',\n",
              "  'plate',\n",
              "  'noodles',\n",
              "  'wound',\n",
              "  'piece',\n",
              "  'light',\n",
              "  'going',\n",
              "  'moon',\n",
              "  'slide',\n",
              "  'spaghetti',\n",
              "  'maybe',\n",
              "  'make',\n",
              "  'j',\n",
              "  'hook',\n",
              "  'end',\n",
              "  'piece',\n",
              "  'light',\n",
              "  'going',\n",
              "  'sun',\n",
              "  'go',\n",
              "  'around',\n",
              "  'whole',\n",
              "  'plate',\n",
              "  'like',\n",
              "  'needle',\n",
              "  'record',\n",
              "  'gets',\n",
              "  'pencil',\n",
              "  'compass',\n",
              "  'rule',\n",
              "  'draw',\n",
              "  'diagram',\n",
              "  'moon',\n",
              "  'big',\n",
              "  'earth',\n",
              "  'shadow',\n",
              "  'upon',\n",
              "  'times',\n",
              "  'totally',\n",
              "  'eclipse',\n",
              "  'sun',\n",
              "  'look',\n",
              "  'sky',\n",
              "  'except',\n",
              "  'knowledge',\n",
              "  'would',\n",
              "  'guess',\n",
              "  'size',\n",
              "  'look',\n",
              "  'size',\n",
              "  'e',\n",
              "  'e',\n",
              "  'full',\n",
              "  'moon',\n",
              "  'quarter',\n",
              "  'moon',\n",
              "  'etc',\n",
              "  'difference',\n",
              "  'rate',\n",
              "  'ether',\n",
              "  'spins',\n",
              "  'looking',\n",
              "  'rotating',\n",
              "  'turntable',\n",
              "  'view',\n",
              "  'moon',\n",
              "  'half',\n",
              "  'facing',\n",
              "  'sun',\n",
              "  'seen',\n",
              "  'half',\n",
              "  'moon',\n",
              "  'within',\n",
              "  'degrees',\n",
              "  'sky',\n",
              "  'sun',\n",
              "  'day',\n",
              "  'try',\n",
              "  'draw',\n",
              "  'earth',\n",
              "  'shadow',\n",
              "  'moon',\n",
              "  'image',\n",
              "  'appears',\n",
              "  'orbit',\n",
              "  'us',\n",
              "  'matter',\n",
              "  'light',\n",
              "  'part',\n",
              "  'part',\n",
              "  'facing',\n",
              "  'sun',\n",
              "  'dark',\n",
              "  'part',\n",
              "  'half',\n",
              "  'facing',\n",
              "  'away',\n",
              "  'sun',\n",
              "  'even',\n",
              "  'appears',\n",
              "  'behind',\n",
              "  'us',\n",
              "  'light',\n",
              "  'years',\n",
              "  'galaxies',\n",
              "  'misnomer',\n",
              "  'distance',\n",
              "  'closer',\n",
              "  'zero',\n",
              "  'time',\n",
              "  'matter',\n",
              "  'characteristics',\n",
              "  'phase',\n",
              "  'reality',\n",
              "  'dissipates',\n",
              "  'outward',\n",
              "  'layer',\n",
              "  'onion',\n",
              "  'defining',\n",
              "  'edge',\n",
              "  'ether',\n",
              "  'spin',\n",
              "  'seeing',\n",
              "  'could',\n",
              "  'essentially',\n",
              "  'happening',\n",
              "  'piece',\n",
              "  'light',\n",
              "  'may',\n",
              "  'experienced',\n",
              "  'many',\n",
              "  'years',\n",
              "  'trip',\n",
              "  'could',\n",
              "  'quick',\n",
              "  'time',\n",
              "  'time',\n",
              "  'travel',\n",
              "  'warp',\n",
              "  'space',\n",
              "  'might',\n",
              "  'consider',\n",
              "  'learning',\n",
              "  'de',\n",
              "  'spin',\n",
              "  'phase',\n",
              "  'mass',\n",
              "  'good',\n",
              "  'luck',\n",
              "  'trying',\n",
              "  'design',\n",
              "  'propulsion',\n",
              "  'system',\n",
              "  'drag',\n",
              "  'around',\n",
              "  'space',\n",
              "  'time',\n",
              "  'locality',\n",
              "  'like',\n",
              "  'trying',\n",
              "  'move',\n",
              "  'balloon',\n",
              "  'shooting',\n",
              "  'squirt',\n",
              "  'gun',\n",
              "  'within',\n",
              "  'find',\n",
              "  'recommend',\n",
              "  'studying',\n",
              "  'history',\n",
              "  'look',\n",
              "  'book',\n",
              "  'life',\n",
              "  'holy',\n",
              "  'grail',\n",
              "  'etc',\n",
              "  'brain',\n",
              "  'waves',\n",
              "  'might',\n",
              "  'carry',\n",
              "  'decipherable',\n",
              "  'data',\n",
              "  'start',\n",
              "  'looking',\n",
              "  'part',\n",
              "  'spectra',\n",
              "  'said',\n",
              "  'unusable',\n",
              "  'due',\n",
              "  'background',\n",
              "  'noise',\n",
              "  'billion',\n",
              "  'humans',\n",
              "  'totally',\n",
              "  'isolate',\n",
              "  'record',\n",
              "  'thinking',\n",
              "  'dog',\n",
              "  'backwards',\n",
              "  'learn',\n",
              "  'read',\n",
              "  'got',\n",
              "  'microsoft',\n",
              "  'holy',\n",
              "  'grail',\n",
              "  'card',\n",
              "  'pentium',\n",
              "  'next',\n",
              "  'concluding',\n",
              "  'thoughts',\n",
              "  'recorded',\n",
              "  'non',\n",
              "  'time',\n",
              "  'bound',\n",
              "  'media',\n",
              "  'ether',\n",
              "  'move',\n",
              "  'forward',\n",
              "  'time',\n",
              "  'would',\n",
              "  'try',\n",
              "  'temporarily',\n",
              "  'locally',\n",
              "  'reverse',\n",
              "  'flow',\n",
              "  'time',\n",
              "  'start',\n",
              "  'looking',\n",
              "  'flowing',\n",
              "  'opposite',\n",
              "  'magnetism',\n",
              "  'pole',\n",
              "  'pole',\n",
              "  'perhaps',\n",
              "  'passing',\n",
              "  'large',\n",
              "  'flat',\n",
              "  'dc',\n",
              "  'current',\n",
              "  'two',\n",
              "  'foot',\n",
              "  'diameter',\n",
              "  'coil',\n",
              "  'choke',\n",
              "  'something',\n",
              "  'seeing',\n",
              "  'could',\n",
              "  'get',\n",
              "  'machine',\n",
              "  'receiver',\n",
              "  'next',\n",
              "  'think',\n",
              "  'live',\n",
              "  'see',\n",
              "  'consider',\n",
              "  'quit',\n",
              "  'putting',\n",
              "  'reproductive',\n",
              "  'keys',\n",
              "  'life',\n",
              "  'body',\n",
              "  'life',\n",
              "  'data',\n",
              "  'could',\n",
              "  'written',\n",
              "  'wind',\n",
              "  'ether',\n",
              "  'thoughts',\n",
              "  'dna',\n",
              "  'could',\n",
              "  'little',\n",
              "  'receiver',\n",
              "  'file',\n",
              "  'access',\n",
              "  'code',\n",
              "  'eating',\n",
              "  'seeds',\n",
              "  'could',\n",
              "  'jamming',\n",
              "  'reception',\n",
              "  'receiving',\n",
              "  'plant',\n",
              "  'instructions',\n",
              "  'try',\n",
              "  'eating',\n",
              "  'seed',\n",
              "  'bearing',\n",
              "  'fruit',\n",
              "  'maybe',\n",
              "  'greek',\n",
              "  'biblical',\n",
              "  'guys',\n",
              "  'live',\n",
              "  'hundreds',\n",
              "  'years',\n",
              "  'curios',\n",
              "  'see',\n",
              "  'ate',\n",
              "  'worry',\n",
              "  'hair',\n",
              "  'stops',\n",
              "  'growing',\n",
              "  'maybe',\n",
              "  'need',\n",
              "  'eat',\n",
              "  'cosmos',\n",
              "  'formed',\n",
              "  'nothing',\n",
              "  'creating',\n",
              "  'matter',\n",
              "  'need',\n",
              "  'enough',\n",
              "  'bounce',\n",
              "  'around',\n",
              "  'household',\n",
              "  'concept',\n",
              "  'immortal',\n",
              "  'come',\n",
              "  'wheat',\n",
              "  'weed',\n",
              "  'programmed',\n",
              "  'pull',\n",
              "  'soil',\n",
              "  'reproduce',\n",
              "  'like',\n",
              "  'hell',\n",
              "  'die',\n",
              "  'warning',\n",
              "  'writing',\n",
              "  'past',\n",
              "  'little',\n",
              "  'dream',\n",
              "  'world',\n",
              "  'near',\n",
              "  'parallel',\n",
              "  'future',\n",
              "  'lying',\n",
              "  'along',\n",
              "  'path',\n",
              "  'history',\n",
              "  'diverged',\n",
              "  'twelve',\n",
              "  'telepathic',\n",
              "  'glowing',\n",
              "  'beings',\n",
              "  'looked',\n",
              "  'like',\n",
              "  'oscar',\n",
              "  'award',\n",
              "  'always',\n",
              "  'dark',\n",
              "  'one',\n",
              "  'looked',\n",
              "  'like',\n",
              "  'us',\n",
              "  'dark',\n",
              "  'one',\n",
              "  'process',\n",
              "  'making',\n",
              "  'others',\n",
              "  'gods',\n",
              "  'teach',\n",
              "  'meant',\n",
              "  'advising',\n",
              "  'past',\n",
              "  'basically',\n",
              "  'manipulated',\n",
              "  'reproducing',\n",
              "  'raising',\n",
              "  'children',\n",
              "  'seed',\n",
              "  'said',\n",
              "  'little',\n",
              "  'ones',\n",
              "  'looked',\n",
              "  'different',\n",
              "  'sub',\n",
              "  'species',\n",
              "  'meant',\n",
              "  'provide',\n",
              "  'service',\n",
              "  'carefully',\n",
              "  'combed',\n",
              "  'history',\n",
              "  'rewriting',\n",
              "  'favor',\n",
              "  'pulling',\n",
              "  'like',\n",
              "  'weed',\n",
              "  'anything',\n",
              "  'compromised',\n",
              "  'control',\n",
              "  'enticed',\n",
              "  'recruits',\n",
              "  'sending',\n",
              "  'visions',\n",
              "  'saying',\n",
              "  'immortality',\n",
              "  'end',\n",
              "  'road',\n",
              "  'twelve',\n",
              "  'souls',\n",
              "  'kill',\n",
              "  'killed',\n",
              "  'amount',\n",
              "  'control',\n",
              "  'could',\n",
              "  'exert',\n",
              "  'finite',\n",
              "  'though',\n",
              "  'every',\n",
              "  'change',\n",
              "  'made',\n",
              "  'void',\n",
              "  'would',\n",
              "  'appear',\n",
              "  'reality',\n",
              "  'universe',\n",
              "  'one',\n",
              "  'day',\n",
              "  'ended',\n",
              "  'meters',\n",
              "  'us',\n",
              "  'seemed',\n",
              "  'odd',\n",
              "  'remember',\n",
              "  'else',\n",
              "  'twelve',\n",
              "  'finally',\n",
              "  'could',\n",
              "  'prune',\n",
              "  'reality',\n",
              "  'stopped',\n",
              "  'beyond',\n",
              "  'fingertips',\n",
              "  'stepped',\n",
              "  'portal',\n",
              "  'past',\n",
              "  'bask',\n",
              "  'created',\n",
              "  'made',\n",
              "  'changes',\n",
              "  'lost',\n",
              "  'body',\n",
              "  'existing',\n",
              "  'wind',\n",
              "  'moral',\n",
              "  'possible',\n",
              "  'eliminate',\n",
              "  'reality',\n",
              "  'souls',\n",
              "  'whose',\n",
              "  'harmony',\n",
              "  'golden',\n",
              "  'rule',\n",
              "  'treat',\n",
              "  'others',\n",
              "  'wish',\n",
              "  'treated',\n",
              "  'e',\n",
              "  'could',\n",
              "  'end',\n",
              "  'along',\n",
              "  'lonely',\n",
              "  'thread',\n",
              "  'time',\n",
              "  'murderers',\n",
              "  'flowery',\n",
              "  'brown',\n",
              "  'nosers',\n",
              "  'playmates',\n",
              "  'eternal',\n",
              "  'one',\n",
              "  'way',\n",
              "  'back',\n",
              "  'accepting',\n",
              "  'rides',\n",
              "  'past',\n",
              "  'one',\n",
              "  'looks',\n",
              "  'like',\n",
              "  'us',\n",
              "  'sells',\n",
              "  'rides',\n",
              "  'make',\n",
              "  'prince',\n",
              "  'queen',\n",
              "  'live',\n",
              "  'god',\n",
              "  'ancient',\n",
              "  'greece',\n",
              "  'go',\n",
              "  'ahead',\n",
              "  'repeat',\n",
              "  'third',\n",
              "  'grade',\n",
              "  'often',\n",
              "  'like',\n",
              "  'adam',\n",
              "  'henry',\n",
              "  'hope',\n",
              "  'like',\n",
              "  'inspecting',\n",
              "  'socks',\n",
              "  'careful',\n",
              "  'though',\n",
              "  'likes',\n",
              "  'work',\n",
              "  'thinks',\n",
              "  'getting',\n",
              "  'wise',\n",
              "  'direct',\n",
              "  'cross',\n",
              "  'paths',\n",
              "  'old',\n",
              "  'self',\n",
              "  'vanish',\n",
              "  'rewrite',\n",
              "  'course',\n",
              "  'history',\n",
              "  'none',\n",
              "  'wiser',\n",
              "  'pass',\n",
              "  'point',\n",
              "  'along',\n",
              "  'parallel',\n",
              "  'line',\n",
              "  'stepped',\n",
              "  'back',\n",
              "  'time',\n",
              "  'hierarchy',\n",
              "  'lose',\n",
              "  'direction',\n",
              "  'still',\n",
              "  'make',\n",
              "  'changes',\n",
              "  'work',\n",
              "  'every',\n",
              "  'adjustment',\n",
              "  'becomes',\n",
              "  'less',\n",
              "  'world',\n",
              "  'cultivated',\n",
              "  'loosens',\n",
              "  'grip',\n",
              "  'organization',\n",
              "  'suddenly',\n",
              "  'one',\n",
              "  'branch',\n",
              "  'less',\n",
              "  'see',\n",
              "  'change',\n",
              "  'basic',\n",
              "  'nature',\n",
              "  'man',\n",
              "  'good',\n",
              "  'apply',\n",
              "  'hand',\n",
              "  'achieve',\n",
              "  'world',\n",
              "  'tightens',\n",
              "  'hand',\n",
              "  'retain',\n",
              "  'built',\n",
              "  'sand',\n",
              "  'slips',\n",
              "  'fingers',\n",
              "  'public',\n",
              "  'computer',\n",
              "  'access',\n",
              "  'r',\n",
              "  'country',\n",
              "  'money',\n",
              "  'spending',\n",
              "  'us',\n",
              "  'right',\n",
              "  'imagine',\n",
              "  'washington',\n",
              "  'marks',\n",
              "  'next',\n",
              "  'cost',\n",
              "  'irs',\n",
              "  'collects',\n",
              "  'gives',\n",
              "  'congress',\n",
              "  'absolutely',\n",
              "  'buries',\n",
              "  'congress',\n",
              "  'borrows',\n",
              "  'banks',\n",
              "  'making',\n",
              "  'margin',\n",
              "  'interest',\n",
              "  'government',\n",
              "  'big',\n",
              "  'corporations',\n",
              "  'ecstatic',\n",
              "  'margin',\n",
              "  'banks',\n",
              "  'hold',\n",
              "  'carrot',\n",
              "  'world',\n",
              "  'sure',\n",
              "  'mostly',\n",
              "  'bury',\n",
              "  'food',\n",
              "  'production',\n",
              "  'gnp',\n",
              "  'construction',\n",
              "  'hours',\n",
              "  'build',\n",
              "  'auto',\n",
              "  'people',\n",
              "  'spending',\n",
              "  'time',\n",
              "  'buy',\n",
              "  'back',\n",
              "  'tenth',\n",
              "  'produce',\n",
              "  'deceived',\n",
              "  'efficient',\n",
              "  'getting',\n",
              "  'harder',\n",
              "  'get',\n",
              "  'point',\n",
              "  'keep',\n",
              "  'people',\n",
              "  'busy',\n",
              "  'making',\n",
              "  'widgets',\n",
              "  'reality',\n",
              "  'shouted',\n",
              "  'twelve',\n",
              "  'chaos',\n",
              "  'said',\n",
              "  'order',\n",
              "  'defined',\n",
              "  'chaos',\n",
              "  'able',\n",
              "  'control',\n",
              "  'rain',\n",
              "  'forest',\n",
              "  'problem',\n",
              "  'could',\n",
              "  'water',\n",
              "  'canopy',\n",
              "  'would',\n",
              "  'hide',\n",
              "  'location',\n",
              "  'indigenous',\n",
              "  'people',\n",
              "  'language',\n",
              "  'telepathic',\n",
              "  'vanishing',\n",
              "  'closest',\n",
              "  'knowledge',\n",
              "  'death',\n",
              "  'think',\n",
              "  'spine',\n",
              "  'transceiver',\n",
              "  'ground',\n",
              "  'pointed',\n",
              "  'locate',\n",
              "  'people',\n",
              "  'probably',\n",
              "  'naive',\n",
              "  'children',\n",
              "  'tough',\n",
              "  'kill',\n",
              "  'also',\n",
              "  'able',\n",
              "  'tell',\n",
              "  'stories',\n",
              "  'dark',\n",
              "  'one',\n",
              "  'talk',\n",
              "  'hear',\n",
              "  'think',\n",
              "  'ham',\n",
              "  'world',\n",
              "  'band',\n",
              "  'radio',\n",
              "  'old',\n",
              "  'timers',\n",
              "  'might',\n",
              "  'story',\n",
              "  'tell',\n",
              "  'people',\n",
              "  'would',\n",
              "  'different',\n",
              "  'frequency',\n",
              "  'us',\n",
              "  'eating',\n",
              "  'seeds',\n",
              "  'famine',\n",
              "  'relief',\n",
              "  'make',\n",
              "  'diet',\n",
              "  'almost',\n",
              "  'whole',\n",
              "  'wheat',\n",
              "  'get',\n",
              "  'huge',\n",
              "  'belly',\n",
              "  'lose',\n",
              "  'muscle',\n",
              "  'mass',\n",
              "  'sleep',\n",
              "  'lot',\n",
              "  'get',\n",
              "  'sick',\n",
              "  'eat',\n",
              "  'fresh',\n",
              "  'fruit',\n",
              "  'get',\n",
              "  'energy',\n",
              "  'hollywood',\n",
              "  'flat',\n",
              "  'belly',\n",
              "  'need',\n",
              "  'lot',\n",
              "  'less',\n",
              "  'sleep',\n",
              "  'un',\n",
              "  'peace',\n",
              "  'keeping',\n",
              "  'fighting',\n",
              "  'killing',\n",
              "  'troops',\n",
              "  'go',\n",
              "  'bread',\n",
              "  'shelf',\n",
              "  'ok',\n",
              "  'kill',\n",
              "  'make',\n",
              "  'sure',\n",
              "  'enough',\n",
              "  'eat',\n",
              "  'somalia',\n",
              "  'disturbing',\n",
              "  'energetic',\n",
              "  'gun',\n",
              "  'carrying',\n",
              "  'three',\n",
              "  'foot',\n",
              "  'tall',\n",
              "  'sixteen',\n",
              "  'year',\n",
              "  'olds',\n",
              "  'eat',\n",
              "  'nothing',\n",
              "  'roots',\n",
              "  ...],\n",
              " ['jennise',\n",
              "  'opus',\n",
              "  'dgi',\n",
              "  'com',\n",
              "  'milady',\n",
              "  'printcap',\n",
              "  'goddess',\n",
              "  'peripherals',\n",
              "  'subject',\n",
              "  'looking',\n",
              "  'little',\n",
              "  'research',\n",
              "  'help',\n",
              "  'organization',\n",
              "  'dynamic',\n",
              "  'graphics',\n",
              "  'inc',\n",
              "  'lines',\n",
              "  'distribution',\n",
              "  'usa',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'opus',\n",
              "  'dgi',\n",
              "  'com',\n",
              "  'hi',\n",
              "  'writing',\n",
              "  'science',\n",
              "  'fiction',\n",
              "  'script',\n",
              "  'looking',\n",
              "  'answers',\n",
              "  'questions',\n",
              "  'regarding',\n",
              "  'moon',\n",
              "  'earth',\n",
              "  'starting',\n",
              "  'point',\n",
              "  'impossible',\n",
              "  'situation',\n",
              "  'checked',\n",
              "  'professor',\n",
              "  'berkeley',\n",
              "  'response',\n",
              "  'helpful',\n",
              "  'happen',\n",
              "  'enjoy',\n",
              "  'playing',\n",
              "  'unusual',\n",
              "  'ideas',\n",
              "  'willing',\n",
              "  'answer',\n",
              "  'questions',\n",
              "  'please',\n",
              "  'contact',\n",
              "  'via',\n",
              "  'e',\n",
              "  'mail',\n",
              "  'jennise',\n",
              "  'dgi',\n",
              "  'com',\n",
              "  'get',\n",
              "  'extremely',\n",
              "  'annoyed',\n",
              "  'screen',\n",
              "  'tele',\n",
              "  'plays',\n",
              "  'ignore',\n",
              "  'basic',\n",
              "  'facts',\n",
              "  'computers',\n",
              "  'determined',\n",
              "  'scientifically',\n",
              "  'accurate',\n",
              "  'sorry',\n",
              "  'vague',\n",
              "  'like',\n",
              "  'protect',\n",
              "  'idea',\n",
              "  'much',\n",
              "  'ready',\n",
              "  'sell',\n",
              "  'hopefully',\n",
              "  'jennise'],\n",
              " ['etxmst',\n",
              "  'sta',\n",
              "  'ericsson',\n",
              "  'se',\n",
              "  'markus',\n",
              "  'strobl',\n",
              "  'subject',\n",
              "  'renting',\n",
              "  'alamo',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'st',\n",
              "  'ericsson',\n",
              "  'se',\n",
              "  'reply',\n",
              "  'etxmst',\n",
              "  'sta',\n",
              "  'ericsson',\n",
              "  'se',\n",
              "  'organization',\n",
              "  'ericsson',\n",
              "  'telecom',\n",
              "  'ab',\n",
              "  'lines',\n",
              "  'hello',\n",
              "  'netters',\n",
              "  'visiting',\n",
              "  'us',\n",
              "  'sweden',\n",
              "  'august',\n",
              "  'probably',\n",
              "  'rent',\n",
              "  'chevy',\n",
              "  'beretta',\n",
              "  'alamo',\n",
              "  'quoted',\n",
              "  'week',\n",
              "  'additional',\n",
              "  'days',\n",
              "  'would',\n",
              "  'include',\n",
              "  'free',\n",
              "  'driving',\n",
              "  'distance',\n",
              "  'local',\n",
              "  'taxes',\n",
              "  'baltimore',\n",
              "  'also',\n",
              "  'told',\n",
              "  'insurance',\n",
              "  'thats',\n",
              "  'necessary',\n",
              "  'included',\n",
              "  'doubt',\n",
              "  'cause',\n",
              "  'friend',\n",
              "  'rented',\n",
              "  'car',\n",
              "  'last',\n",
              "  'year',\n",
              "  'turned',\n",
              "  'needed',\n",
              "  'lot',\n",
              "  'insurance',\n",
              "  'included',\n",
              "  'base',\n",
              "  'price',\n",
              "  'hand',\n",
              "  'rent',\n",
              "  'alamo',\n",
              "  'anyone',\n",
              "  'info',\n",
              "  'rip',\n",
              "  'probability',\n",
              "  'needing',\n",
              "  'insurance',\n",
              "  'beretta',\n",
              "  'good',\n",
              "  'rental',\n",
              "  'car',\n",
              "  'thanx',\n",
              "  'markus'],\n",
              " ['parr',\n",
              "  'acs',\n",
              "  'ucalgary',\n",
              "  'ca',\n",
              "  'charles',\n",
              "  'parr',\n",
              "  'subject',\n",
              "  'hell',\n",
              "  'mets',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'acs',\n",
              "  'acs',\n",
              "  'ucalgary',\n",
              "  'ca',\n",
              "  'organization',\n",
              "  'university',\n",
              "  'calgary',\n",
              "  'alberta',\n",
              "  'lines',\n",
              "  'article',\n",
              "  'mavenry',\n",
              "  'altcit',\n",
              "  'eskimo',\n",
              "  'com',\n",
              "  'maven',\n",
              "  'mavenry',\n",
              "  'altcit',\n",
              "  'eskimo',\n",
              "  'com',\n",
              "  'norman',\n",
              "  'hamer',\n",
              "  'writes',\n",
              "  'talked',\n",
              "  'couple',\n",
              "  'people',\n",
              "  'helmets',\n",
              "  'dropping',\n",
              "  'getting',\n",
              "  'sweat',\n",
              "  'might',\n",
              "  'think',\n",
              "  'replacing',\n",
              "  'ride',\n",
              "  'go',\n",
              "  'without',\n",
              "  'helmet',\n",
              "  'first',\n",
              "  'way',\n",
              "  'tell',\n",
              "  'helmet',\n",
              "  'damaged',\n",
              "  'structurally',\n",
              "  'dropped',\n",
              "  'feet',\n",
              "  'cement',\n",
              "  'seat',\n",
              "  'chipped',\n",
              "  'paint',\n",
              "  'seem',\n",
              "  'screw',\n",
              "  'actual',\n",
              "  'shell',\n",
              "  'bet',\n",
              "  'price',\n",
              "  'helmet',\n",
              "  'okay',\n",
              "  'feet',\n",
              "  'higher',\n",
              "  'maybe',\n",
              "  'end',\n",
              "  'replacing',\n",
              "  'real',\n",
              "  'near',\n",
              "  'future',\n",
              "  'would',\n",
              "  'better',\n",
              "  'wear',\n",
              "  'totally',\n",
              "  'nondamaged',\n",
              "  'face',\n",
              "  'dot',\n",
              "  'rated',\n",
              "  'cheapie',\n",
              "  'fit',\n",
              "  'well',\n",
              "  'keep',\n",
              "  'wind',\n",
              "  'well',\n",
              "  'wearing',\n",
              "  'shoei',\n",
              "  'rf',\n",
              "  'lot',\n",
              "  'comfortable',\n",
              "  'keeps',\n",
              "  'wind',\n",
              "  'better',\n",
              "  'quieter',\n",
              "  'might',\n",
              "  'minor',\n",
              "  'damage',\n",
              "  'wear',\n",
              "  'full',\n",
              "  'facer',\n",
              "  'way',\n",
              "  'worried',\n",
              "  'wind',\n",
              "  'blast',\n",
              "  'face',\n",
              "  'inability',\n",
              "  'hear',\n",
              "  'police',\n",
              "  'sirens',\n",
              "  'helmet',\n",
              "  'little',\n",
              "  'damaged',\n",
              "  'also',\n",
              "  'would',\n",
              "  'reccomend',\n",
              "  'far',\n",
              "  'good',\n",
              "  'helmets',\n",
              "  'slightly',\n",
              "  'disappointed',\n",
              "  'badly',\n",
              "  'shoei',\n",
              "  'scratched',\n",
              "  'etc',\n",
              "  'bloody',\n",
              "  'careful',\n",
              "  'little',\n",
              "  'impact',\n",
              "  'took',\n",
              "  'chip',\n",
              "  'paint',\n",
              "  'arguably',\n",
              "  'mess',\n",
              "  'period',\n",
              "  'looking',\n",
              "  'really',\n",
              "  'good',\n",
              "  'full',\n",
              "  'face',\n",
              "  'good',\n",
              "  'venting',\n",
              "  'wind',\n",
              "  'protection',\n",
              "  'like',\n",
              "  'shoei',\n",
              "  'style',\n",
              "  'kinda',\n",
              "  'like',\n",
              "  'norton',\n",
              "  'one',\n",
              "  'saw',\n",
              "  'awhile',\n",
              "  'back',\n",
              "  'suspect',\n",
              "  'going',\n",
              "  'get',\n",
              "  'much',\n",
              "  'expensive',\n",
              "  'helmet',\n",
              "  'want',\n",
              "  'replace',\n",
              "  'every',\n",
              "  'time',\n",
              "  'careful',\n",
              "  'set',\n",
              "  'well',\n",
              "  'next',\n",
              "  'helmet',\n",
              "  'subject',\n",
              "  'fitting',\n",
              "  'well',\n",
              "  'agv',\n",
              "  'sukhoi',\n",
              "  'like',\n",
              "  'looks',\n",
              "  'current',\n",
              "  'one',\n",
              "  'shoei',\n",
              "  'task',\n",
              "  'getting',\n",
              "  'little',\n",
              "  'old',\n",
              "  'crashed',\n",
              "  'couple',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'hard',\n",
              "  'impact',\n",
              "  'head',\n",
              "  'hip',\n",
              "  'took',\n",
              "  'care',\n",
              "  'price',\n",
              "  'consideration',\n",
              "  'get',\n",
              "  'kiwi',\n",
              "  'k',\n",
              "  'hear',\n",
              "  'good',\n",
              "  'cheap',\n",
              "  'christ',\n",
              "  'treat',\n",
              "  'head',\n",
              "  'carefully',\n",
              "  'treated',\n",
              "  'shoei',\n",
              "  'far',\n",
              "  'tossing',\n",
              "  'bruises',\n",
              "  'mildly',\n",
              "  'mildly',\n",
              "  'paranoid',\n",
              "  'helmet',\n",
              "  'get',\n",
              "  'carried',\n",
              "  'away',\n",
              "  'people',\n",
              "  'net',\n",
              "  'like',\n",
              "  'mentioned',\n",
              "  'consistently',\n",
              "  'live',\n",
              "  'planet',\n",
              "  'regards',\n",
              "  'charles',\n",
              "  'dod',\n",
              "  'rz',\n",
              "  'within',\n",
              "  'span',\n",
              "  'last',\n",
              "  'weeks',\n",
              "  'heard',\n",
              "  'elements',\n",
              "  'separate',\n",
              "  'threads',\n",
              "  'conjoined',\n",
              "  'time',\n",
              "  'struck',\n",
              "  'together',\n",
              "  'form',\n",
              "  'new',\n",
              "  'chord',\n",
              "  'within',\n",
              "  'hollow',\n",
              "  'echoing',\n",
              "  'gourd',\n",
              "  'unknown',\n",
              "  'net',\n",
              "  'person']]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_imdb = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLEebm1K7L41",
        "outputId": "7f1d5741-4138-4f5d-e06a-44e493c75ea2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.79 s, sys: 33.6 ms, total: 6.82 s\n",
            "Wall time: 4.21 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим, что модель обучилась\n",
        "print(model_imdb.wv.most_similar(positive=['find'], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klyXfeAR7SeB",
        "outputId": "28ec94a2-4878-49fe-c1a5-acdae56bc6f8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('try', 0.9775561094284058), ('make', 0.9725176095962524), ('used', 0.9700536727905273), ('look', 0.9699898362159729), ('either', 0.9608041644096375)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_2(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LjM2Ehr-7W0K"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Проверка качества работы модели word2vec"
      ],
      "metadata": {
        "id": "9yUJ1Ynz_2DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    '''\n",
        "    Для текста усредним вектора входящих в него слов\n",
        "    '''\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean(\n",
        "            [self.model[w] for w in words if w in self.model] \n",
        "            or [np.zeros(self.size)], axis=0)\n",
        "            for words in X])"
      ],
      "metadata": {
        "id": "cL1m4h3M7eMo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "iNEtVYom7iCJ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучающая и тестовая выборки\n",
        "boundary = 1500\n",
        "X_train = corpus[:boundary] \n",
        "X_test = corpus[boundary:]\n",
        "y_train = newsgroups['target'][:boundary]\n",
        "y_test = newsgroups['target'][boundary:]"
      ],
      "metadata": {
        "id": "BLZ9TMCd7ksg"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_2(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBvQx4dv73ls",
        "outputId": "18dffe8a-fe6c-415d-9caa-3f0a6b78bfda"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9571428571428572\n",
            "1 \t 0.7252252252252253\n",
            "2 \t 0.7746478873239436\n",
            "3 \t 0.9055793991416309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как видно из результатов проверки качества моделей, лучшее качество показал CountVectorizer**"
      ],
      "metadata": {
        "id": "gSFLRV1Cw7pL"
      }
    }
  ]
}